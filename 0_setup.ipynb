{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "In this notebook, we set up the databases we need for the LCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bd\n",
    "import bw2io as bi\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.projects.set_current(\"paper_plca_grid_expansion_rev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating background databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For creating the background databases, we need access to the ecoinvent database (commercial) and to the default premise scenarios (free, to be asked from premise maintainers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoinvent_username = \"xxx\" # fill in your data here\n",
    "ecoinvent_password = \"xxx\"\n",
    "premise_key = \"xxx\" # to be asked from premise maintainers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ecoinvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi.import_ecoinvent_release(\n",
    "    version=\"3.10.1\",\n",
    "    system_model=\"cutoff\",\n",
    "    username=ecoinvent_username,\n",
    "    password=ecoinvent_password,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating prospective databases with `premise`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from premise import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb = NewDatabase(\n",
    "    scenarios=[\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg1000\", \"year\": 2023},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg1000\", \"year\": 2025},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg1000\", \"year\": 2030},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg1000\", \"year\": 2035},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg1000\", \"year\": 2037},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg1000\", \"year\": 2040},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg1000\", \"year\": 2045},\n",
    "        \n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg650\", \"year\": 2023},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg650\", \"year\": 2025},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg650\", \"year\": 2030},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg650\", \"year\": 2035},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg650\", \"year\": 2037},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg650\", \"year\": 2040},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-PkBudg650\", \"year\": 2045},\n",
    "        \n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-NPi\", \"year\": 2023},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-NPi\", \"year\": 2025},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-NPi\", \"year\": 2030},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-NPi\", \"year\": 2035},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-NPi\", \"year\": 2037},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-NPi\", \"year\": 2040},\n",
    "        {\"model\": \"remind-eu\", \"pathway\": \"SSP2-NPi\", \"year\": 2045},\n",
    "    ],\n",
    "    source_db=\"ecoinvent-3.10.1-cutoff\",  # <-- name of the database in the BW2 project. Must be a string.\n",
    "    source_version=\"3.10\",  # <-- version of ecoinvent. Can be \"3.8\", \"3.9\" or \"3.10\". Must be a string.\n",
    "    key=premise_key,  # to be requested from the library maintainers if you want to use default scenarios included in `premise`\n",
    "    biosphere_name=\"ecoinvent-3.10.1-biosphere\",  # <-- name of the biosphere database in the BW2 project. Must be a string.\n",
    ")\n",
    "\n",
    "ndb.update()\n",
    "\n",
    "db_names = [\n",
    "    \"ei310_SSP2_PkBudg1000_2023\",\n",
    "    \"ei310_SSP2_PkBudg1000_2025\",\n",
    "    \"ei310_SSP2_PkBudg1000_2030\",\n",
    "    \"ei310_SSP2_PkBudg1000_2035\",\n",
    "    \"ei310_SSP2_PkBudg1000_2037\",\n",
    "    \"ei310_SSP2_PkBudg1000_2040\",\n",
    "    \"ei310_SSP2_PkBudg1000_2045\",\n",
    "    \"ei310_SSP2_PkBudg650_2023\",\n",
    "    \"ei310_SSP2_PkBudg650_2025\",\n",
    "    \"ei310_SSP2_PkBudg650_2030\",\n",
    "    \"ei310_SSP2_PkBudg650_2035\",\n",
    "    \"ei310_SSP2_PkBudg650_2037\",\n",
    "    \"ei310_SSP2_PkBudg650_2040\",\n",
    "    \"ei310_SSP2_PkBudg650_2045\",\n",
    "    \"ei310_SSP2_NPi_2023\",\n",
    "    \"ei310_SSP2_NPi_2025\",\n",
    "    \"ei310_SSP2_NPi_2030\",\n",
    "    \"ei310_SSP2_NPi_2035\",\n",
    "    \"ei310_SSP2_NPi_2037\",\n",
    "    \"ei310_SSP2_NPi_2040\",\n",
    "    \"ei310_SSP2_NPi_2045\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.write_db_to_brightway(db_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding premise_gwp LCIA method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from premise_gwp import add_premise_gwp\n",
    "add_premise_gwp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the grid databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "\n",
    "First, we load the background activities from ecoinvent. We write a function for this, as we need to do this for all our different background databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inputs_from_background(database_name: str):\n",
    "    db = bd.Database(database_name)\n",
    "    return {\n",
    "        \"glass_wool_mat\": db.get(name=\"market for glass wool mat\", location=\"GLO\"),\n",
    "        \"porcelain\": db.get(name=\"market for ceramic tile\", location=\"GLO\"),\n",
    "        \"epoxy\": db.get(name=\"market for epoxy resin, liquid\", location=\"RER\"),\n",
    "        \"brass\": db.get(name=\"market for brass\", location=\"RoW\"),\n",
    "        \"paint\": db.get(name=\"market for electrostatic paint\", location=\"GLO\"),\n",
    "        \"paper\": db.get(name=\"market for paper, melamine impregnated\", location=\"RER\"),\n",
    "        \"rubber\": db.get(name=\"market for synthetic rubber\", location=\"GLO\"),\n",
    "        \"sulfur_hexafluoride\": db.get(\n",
    "            name=\"market for sulfur hexafluoride, liquid\", location=\"RER\"\n",
    "        ),\n",
    "        \"lead\": db.get(name=\"market for lead\", location=\"GLO\"),\n",
    "        \"bronze\": db.get(name=\"market for bronze\", location=\"GLO\"),\n",
    "        \"polypropylene\": db.get(\n",
    "            name=\"market for polypropylene, granulate\", location=\"GLO\"\n",
    "        ),\n",
    "        \"steel_sheet\": db.get(name=\"market for sheet rolling, steel\", location=\"GLO\"),\n",
    "        \"steel_hot_rolled\": db.get(\n",
    "            name=\"market for steel, low-alloyed, hot rolled\", location=\"GLO\"\n",
    "        ),\n",
    "        \"steel_lowalloyed\": db.get(\n",
    "            name=\"market for steel, low-alloyed\", location=\"GLO\"\n",
    "        ),\n",
    "        \"steel_unalloyed\": db.get(name=\"market for steel, unalloyed\", location=\"GLO\"),\n",
    "        \"transformer_oil\": db.get(name=\"market for lubricating oil\", location=\"RER\"),\n",
    "        \"aluminium_wrought_alloy\": db.get(\n",
    "            name=\"market for aluminium, wrought alloy\", location=\"GLO\"\n",
    "        ),\n",
    "        \"aluminium_sheet\": db.get(\n",
    "            name=\"market for sheet rolling, aluminium\", location=\"GLO\"\n",
    "        ),\n",
    "        \"aluminium_cast\": db.get(\n",
    "            name=\"market for aluminium, cast alloy\", location=\"GLO\"\n",
    "        ),\n",
    "        \"copper\": db.get(name=\"market for copper, cathode\", location=\"GLO\"),\n",
    "        \"copper_wire\": db.get(name=\"wire drawing, copper\", location=\"RER\"),\n",
    "        \"glass_fibre\": db.get(name=\"market for glass fibre\", location=\"GLO\"),\n",
    "        \"kraft_paper\": db.get(name=\"market for kraft paper\", location=\"RER\"),\n",
    "        \"softwood\": db.get(\n",
    "            name=\"market for sawnwood, softwood, raw, dried (u=20%)\", location=\"RER\"\n",
    "        ),\n",
    "        \"concrete\": db.get(\n",
    "            name=\"market for concrete, normal strength\", location=\"RoW\"\n",
    "        ),  # density of 2200 kg/m3 assumed for conversion, see Itten et al.\n",
    "        \"zinc\": db.get(name=\"market for zinc\", location=\"GLO\"),\n",
    "        \"waste_concrete\": db.get(\n",
    "            name=\"market for waste concrete\", location=\"Europe without Switzerland\"\n",
    "        ),\n",
    "        \"waste_polyethylene\": db.get(\n",
    "            name=\"market for waste polyethylene\", location=\"DE\"\n",
    "        ),\n",
    "        \"waste_oil\": db.get(\n",
    "            name=\"market for waste mineral oil\", location=\"Europe without Switzerland\"\n",
    "        ),\n",
    "        \"excavation\": db.get(\n",
    "            name=\"market for excavation, hydraulic digger\", location=\"GLO\"\n",
    "        ),\n",
    "        \"polyester_resin\": db.get(\n",
    "            name=\"market for polyester resin, unsaturated\", location=\"RER\"\n",
    "        ),\n",
    "        \"steel_chromium_steel\": db.get(\n",
    "            name=\"market for steel, chromium steel 18/8\", location=\"GLO\"\n",
    "        ),\n",
    "        \"polycarbonate\": db.get(name=\"market for polycarbonate\", location=\"RER\"),\n",
    "        \"wood\": db.get(name=\"market for fibreboard, hard\", location=\"RER\"),\n",
    "        \"cement_unspecified\": db.get(\n",
    "            name=\"market for cement, unspecified\", location=\"Europe without Switzerland\"\n",
    "        ),\n",
    "        \"glass_tube_borosilicate\": db.get(\n",
    "            name=\"market for glass tube, borosilicate\", location=\"GLO\"\n",
    "        ),\n",
    "        \"extrusion_plastic_pipes\": db.get(\n",
    "            name=\"market for extrusion, plastic pipes\", location=\"GLO\"\n",
    "        ),\n",
    "        \"polyethylene\": db.get(\n",
    "            name=\"market for polyethylene, low density, granulate\", location=\"GLO\"\n",
    "        ),\n",
    "        \"copper_wire_drawing\": db.get(\n",
    "            name=\"market for wire drawing, copper\", location=\"GLO\"\n",
    "        ),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata for the grid components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (code, name, unit) of grid components\n",
    "COMPONENT_INFO = [\n",
    "    (\"disconnector\", \"Disconnector\", \"unit\"),\n",
    "    (\n",
    "        \"land_cable_oil_cu_150kv\",\n",
    "        \"Land cable, oil insulated, copper, 150kV\",\n",
    "        \"kilometer\",\n",
    "    ),\n",
    "    (\"overhead_line_400kv\", \"Overhead line, 400kV\", \"kilometer\"),\n",
    "    (\"overhead_line_150kv\", \"Overhead line, 150kV\", \"kilometer\"),\n",
    "    (\"overhead_line_10kv\", \"Overhead line, 10kV\", \"kilometer\"),\n",
    "    (\"overhead_line_04kv\", \"Overhead line, 0.4kV\", \"kilometer\"),\n",
    "    (\"overhead_line_HVDC\", \"Overhead line HVDC\", \"kilometer\"),\n",
    "    (\"land_cable_oil_cu_HVDC\", \"Land cable, oil insulated, copper, HVDC\", \"kilometer\"),\n",
    "    (\"transformer_250mva\", \"Transformer, 250MVA\", \"unit\"),\n",
    "    (\"transformer_40mva\", \"Transformer, 40MVA\", \"unit\"),\n",
    "    (\"transformer_315kva\", \"Transformer, 315kVA\", \"unit\"),\n",
    "    (\n",
    "        \"land_cable_vpe_al_04kv\",\n",
    "        \"Land cable, vpe insulated, aluminium, 0.4kV\",\n",
    "        \"kilometer\",\n",
    "    ),\n",
    "    (\n",
    "        \"land_cable_vpe_al_10kv\",\n",
    "        \"Land cable, vpe insulated, aluminium, 10kV\",\n",
    "        \"kilometer\",\n",
    "    ),\n",
    "    (\n",
    "        \"land_cable_vpe_al_10kv\",\n",
    "        \"Land cable, vpe insulated, aluminium, 10kV\",\n",
    "        \"kilometer\",\n",
    "    ),\n",
    "    (\"land_cable_epr_cu_11kv\", \"Land cable, epr insulated, copper, 11kV\", \"kilometer\"),\n",
    "    (\n",
    "        \"land_cable_vpe_al_50kv\",\n",
    "        \"Land cable, vpe insulated, aluminium, 50kV\",\n",
    "        \"kilometer\",\n",
    "    ),\n",
    "    (\"land_cable_vpe_cu_1kv\", \"Land cable, vpe insulated, copper, 1kV\", \"kilometer\"),\n",
    "    (\"gas_insulated_switchgear_420kv\", \"Gas insulated switchgear, 420kV\", \"unit\"),\n",
    "    (\"substation_lv\", \"Substation, LV\", \"unit\"),\n",
    "    (\"substation_mv\", \"Substation, MV\", \"unit\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to help create the grid component activities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_component_nodes(base_database_name: str, component_database_name: str, reset: bool=True):\n",
    "    if reset:\n",
    "        if component_database_name in bd.databases:\n",
    "            del bd.databases[component_database_name]\n",
    "        db_components = bd.Database(component_database_name)\n",
    "        db_components.register()\n",
    "    else :\n",
    "        db_components = bd.Database(component_database_name)\n",
    "    \n",
    "    INPUT_NODES = load_inputs_from_background(base_database_name)\n",
    "    \n",
    "    for code, name, unit in COMPONENT_INFO:\n",
    "        try:\n",
    "            component = db_components.new_node(\n",
    "                code=code, name=name, unit=unit, **{\"reference product\": name}\n",
    "            )\n",
    "        except:\n",
    "            db_components.get(code).delete()\n",
    "            component = db_components.new_node(\n",
    "                code=code, name=name, unit=unit, **{\"reference product\": name}\n",
    "            )\n",
    "            component.save()\n",
    "        component.save()\n",
    "        component.new_edge(\n",
    "            name=component[\"name\"], input=component, amount=1, unit=unit, type=\"production\"\n",
    "        ).save()\n",
    "\n",
    "        inputs_df = pd.read_csv(f\"data/lci/{code}.csv\", sep=\";\", index_col=\"input\")\n",
    "        for input_code, amount, unit in zip(inputs_df.index, inputs_df.amount, inputs_df.unit):\n",
    "            component.new_edge(\n",
    "                input=INPUT_NODES[input_code], amount=amount, type=\"technosphere\"\n",
    "            ).save()\n",
    "\n",
    "        if code == \"gas_insulated_switchgear_420kv\":\n",
    "            sf6_node = bd.get_node(database=\"ecoinvent-3.10.1-biosphere\", name=\"Sulfur hexafluoride\", categories=(\"air\",))\n",
    "            component.new_edge(\n",
    "                input=sf6_node,\n",
    "                amount=28.6, # leakage\n",
    "                type=\"biosphere\",\n",
    "            ).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need the grid expansion numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bd\n",
    "\n",
    "# Base share values (central estimates)\n",
    "SHARE_DEFAULTS = {\n",
    "    \"oh\": {  # Overhead lines\n",
    "        \"ehv_ac\": 1.0,\n",
    "        \"ehv_dc\": 0.05,\n",
    "        \"hv\": 0.9474,\n",
    "        \"mv\": 0.1847,\n",
    "        \"lv\": 0.0652,\n",
    "    },\n",
    "    \"al\": {  # Aluminum cables\n",
    "        \"ehv\": 0.0,\n",
    "        \"hv\": 0.5,\n",
    "        \"mv\": 0.75,\n",
    "        \"lv\": 0.75,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Total infrastructure quantities per BASE year (km or units)\n",
    "# Note: Interpolated years (2025, 2030, 2035, 2040) get their totals from distributed_components\n",
    "TOTAL_QUANTITIES = {\n",
    "    2023: {\n",
    "        \"ehv_ac\": 36400, \"ehv_dc\": 2172, \"hv\": 95200, \"mv\": 530200, \"lv\": 1570100,\n",
    "        \"transformer_250mva\": 709, \"transformer_40mva\": 7278, \"transformer_315kva\": 577790,\n",
    "        \"gas_insulated_switchgear_420kv\": 7278, \"substation_mv\": 7278 + 709, \"substation_lv\": 577790,\n",
    "        \"land_cable_epr_cu_11kv\": 117593,\n",
    "    },\n",
    "    2037: {\n",
    "        \"ehv_ac\": 11823, \"ehv_dc\": 17492, \"hv\": 28307, \"mv\": 117593, \"lv\": 375511,\n",
    "        \"transformer_250mva\": 221, \"transformer_40mva\": 1890, \"transformer_315kva\": 133273,\n",
    "        \"gas_insulated_switchgear_420kv\": 1890, \"substation_mv\": (1890+709)/1.58, \"substation_lv\": 133273,\n",
    "        \"land_cable_epr_cu_11kv\": 117593,\n",
    "    },\n",
    "    2045: {\n",
    "        \"ehv_ac\": 250, \"ehv_dc\": 4683, \"hv\": 15096, \"mv\": 64837, \"lv\": 198933,\n",
    "        \"transformer_250mva\": 59, \"transformer_40mva\": 1022, \"transformer_315kva\": 71943,\n",
    "        \"gas_insulated_switchgear_420kv\": 1022, \"substation_mv\": (1022+709)/1.58, \"substation_lv\": 71943,\n",
    "        \"land_cable_epr_cu_11kv\": 117593,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Component to voltage level mapping for parameter lookup\n",
    "# Format: component_key -> (param_type, level)\n",
    "# param_type: \"oh\" = overhead line, \"oh_al\" = underground (aluminum or copper)\n",
    "COMPONENT_LEVEL_MAP = {\n",
    "    \"overhead_line_400kv\": (\"oh\", \"ehv_ac\"),\n",
    "    \"overhead_line_HVDC\": (\"oh\", \"ehv_dc\"),\n",
    "    \"overhead_line_150kv\": (\"oh\", \"hv\"),\n",
    "    \"overhead_line_10kv\": (\"oh\", \"mv\"),\n",
    "    \"overhead_line_04kv\": (\"oh\", \"lv\"),\n",
    "    \"land_cable_oil_cu_HVDC\": (\"ug_cu\", \"ehv_dc\"),  # underground copper (HVDC)\n",
    "    \"land_cable_vpe_al_50kv\": (\"ug_al\", \"hv\"),      # underground aluminum\n",
    "    \"land_cable_oil_cu_150kv\": (\"ug_cu\", \"hv\"),    # underground copper\n",
    "    \"land_cable_vpe_al_10kv\": (\"ug_al\", \"mv\"),\n",
    "    \"land_cable_epr_cu_11kv\": (\"ug_cu\", \"mv\"),\n",
    "    \"land_cable_vpe_al_04kv\": (\"ug_al\", \"lv\"),\n",
    "    \"land_cable_vpe_cu_1kv\": (\"ug_cu\", \"lv\"),\n",
    "}\n",
    "\n",
    "def calculate_uncertainty_range(year):\n",
    "    \"\"\"\n",
    "    Calculate the percentage deviation for uncertainty bounds.\n",
    "    Progressive uncertainty: 5% in 2023, linearly increasing to 20% by 2045.\n",
    "    \"\"\"\n",
    "    min_year, max_year = 2023, 2045\n",
    "    min_uncertainty, max_uncertainty = 0.05, 0.20\n",
    "    \n",
    "    # Clamp year to range\n",
    "    year = max(min_year, min(max_year, year))\n",
    "    \n",
    "    # Linear interpolation\n",
    "    progress = (year - min_year) / (max_year - min_year)\n",
    "    return min_uncertainty + progress * (max_uncertainty - min_uncertainty)\n",
    "\n",
    "\n",
    "def setup_project_parameters(years):\n",
    "    \"\"\"\n",
    "    Registers year-specific parameters in the Brightway project.\n",
    "    Uses triangular distribution (uncertainty_type=5) with progressive uncertainty.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    \n",
    "    for year in years:\n",
    "        uncertainty_pct = calculate_uncertainty_range(year)\n",
    "        \n",
    "        # Overhead Line Share parameters\n",
    "        for lvl, val in SHARE_DEFAULTS[\"oh\"].items():\n",
    "            if val == 1.0:\n",
    "                minimum = max(0.0, val - uncertainty_pct)\n",
    "                maximum = 1.0\n",
    "            elif val == 0.0:\n",
    "                minimum = 0.0\n",
    "                maximum = min(1.0, val + uncertainty_pct)\n",
    "            else:\n",
    "                minimum = max(0.0, val * (1 - uncertainty_pct))\n",
    "                maximum = min(1.0, val * (1 + uncertainty_pct))\n",
    "            \n",
    "            params.append({\n",
    "                \"name\": f\"share_oh_{lvl}_{year}\",\n",
    "                \"amount\": val,\n",
    "                \"uncertainty type\": 5,  # Triangular distribution\n",
    "                \"loc\": val,\n",
    "                \"minimum\": minimum,\n",
    "                \"maximum\": maximum,\n",
    "            })\n",
    "        \n",
    "        # Aluminum Cable Share parameters\n",
    "        for lvl, val in SHARE_DEFAULTS[\"al\"].items():\n",
    "            if val == 1.0:\n",
    "                minimum = max(0.0, val - uncertainty_pct)\n",
    "                maximum = 1.0\n",
    "            elif val == 0.0:\n",
    "                minimum = 0.0\n",
    "                maximum = min(1.0, val + uncertainty_pct)\n",
    "            else:\n",
    "                minimum = max(0.0, val * (1 - uncertainty_pct))\n",
    "                maximum = min(1.0, val * (1 + uncertainty_pct))\n",
    "            \n",
    "            params.append({\n",
    "                \"name\": f\"share_al_{lvl}_{year}\",\n",
    "                \"amount\": val,\n",
    "                \"uncertainty type\": 5,\n",
    "                \"loc\": val,\n",
    "                \"minimum\": minimum,\n",
    "                \"maximum\": maximum,\n",
    "            })\n",
    "    \n",
    "    # Register parameters in the project\n",
    "    bd.parameters.new_project_parameters(params)\n",
    "    print(f\"Registered {len(params)} parameters for years: {years}\")\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_base_total_for_component(component, current_value, year):\n",
    "    \"\"\"\n",
    "    Calculate the base total (before share multiplication) for a component.\n",
    "    This reverses the share calculation to get the original total.\n",
    "    \n",
    "    For interpolated years, we use the current_value and reverse-engineer the total.\n",
    "    \"\"\"\n",
    "    if component not in COMPONENT_LEVEL_MAP:\n",
    "        return None\n",
    "    \n",
    "    param_type, level = COMPONENT_LEVEL_MAP[component]\n",
    "    oh_share = SHARE_DEFAULTS[\"oh\"].get(level, 0)\n",
    "    al_level = \"ehv\" if level == \"ehv_dc\" else level\n",
    "    al_share = SHARE_DEFAULTS[\"al\"].get(al_level, 0)\n",
    "    \n",
    "    # Reverse the share calculation to get the base total\n",
    "    if param_type == \"oh\":\n",
    "        # current_value = oh_share * total\n",
    "        if oh_share > 0:\n",
    "            return current_value / oh_share\n",
    "        return current_value\n",
    "    elif param_type == \"ug_cu\":\n",
    "        # For HVDC: current_value = (1 - oh_share) * total\n",
    "        # For others: current_value = (1 - oh_share) * (1 - al_share) * total\n",
    "        if level == \"ehv_dc\":\n",
    "            if (1 - oh_share) > 0:\n",
    "                return current_value / (1 - oh_share)\n",
    "        else:\n",
    "            divisor = (1 - oh_share) * (1 - al_share)\n",
    "            if divisor > 0:\n",
    "                return current_value / divisor\n",
    "        return current_value\n",
    "    elif param_type == \"ug_al\":\n",
    "        # current_value = (1 - oh_share) * al_share * total\n",
    "        divisor = (1 - oh_share) * al_share\n",
    "        if divisor > 0:\n",
    "            return current_value / divisor\n",
    "        return current_value\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_formula_for_component(component, year, current_value):\n",
    "    \"\"\"\n",
    "    Constructs the formula string for an exchange based on the component type.\n",
    "    \n",
    "    Args:\n",
    "        component: The component key (e.g., \"overhead_line_400kv\")\n",
    "        year: The year for parameter lookup\n",
    "        current_value: The pre-computed value from distributed_components\n",
    "    \n",
    "    Logic:\n",
    "    - Overhead Line: share_oh * total\n",
    "    - Al Cable: (1 - share_oh) * share_al * total  \n",
    "    - Cu Cable: (1 - share_oh) * (1 - share_al) * total\n",
    "    \"\"\"\n",
    "    if component not in COMPONENT_LEVEL_MAP:\n",
    "        return None  # Fixed components (transformers, substations)\n",
    "    \n",
    "    param_type, level = COMPONENT_LEVEL_MAP[component]\n",
    "    \n",
    "    # Calculate the base total from the current value\n",
    "    total = get_base_total_for_component(component, current_value, year)\n",
    "    \n",
    "    if total is None or total == 0:\n",
    "        return None\n",
    "    \n",
    "    # Map level names for AL parameters (ehv_dc uses 'ehv')\n",
    "    al_level = \"ehv\" if level == \"ehv_dc\" else level\n",
    "    \n",
    "    if param_type == \"oh\":\n",
    "        # Pure overhead line: share_oh * total\n",
    "        return f\"share_oh_{level}_{year} * {total}\"\n",
    "    \n",
    "    elif param_type == \"ug_cu\":\n",
    "        if level == \"ehv_dc\":\n",
    "            # HVDC underground: (1 - share_oh) * total (no aluminum option)\n",
    "            return f\"(1 - share_oh_{level}_{year}) * {total}\"\n",
    "        else:\n",
    "            # Copper cable: (1 - share_oh) * (1 - share_al) * total\n",
    "            return f\"(1 - share_oh_{level}_{year}) * (1 - share_al_{al_level}_{year}) * {total}\"\n",
    "    \n",
    "    elif param_type == \"ug_al\":\n",
    "        # Aluminum cable: (1 - share_oh) * share_al * total\n",
    "        return f\"(1 - share_oh_{level}_{year}) * share_al_{al_level}_{year} * {total}\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# Build grid_compositions dictionary with computed values\n",
    "# (These are the deterministic values; formulas will be applied to exchanges)\n",
    "grid_compositions = {}\n",
    "\n",
    "for year in [2023, 2037, 2045]:\n",
    "    q = TOTAL_QUANTITIES[year]\n",
    "    oh = SHARE_DEFAULTS[\"oh\"]\n",
    "    al = SHARE_DEFAULTS[\"al\"]\n",
    "    \n",
    "    grid_compositions[year] = {\n",
    "        # EHV AC\n",
    "        \"overhead_line_400kv\": oh[\"ehv_ac\"] * q[\"ehv_ac\"],\n",
    "        # EHV DC\n",
    "        \"overhead_line_HVDC\": oh[\"ehv_dc\"] * q[\"ehv_dc\"],\n",
    "        \"land_cable_oil_cu_HVDC\": (1 - oh[\"ehv_dc\"]) * q[\"ehv_dc\"],\n",
    "        # HV\n",
    "        \"overhead_line_150kv\": oh[\"hv\"] * q[\"hv\"],\n",
    "        \"land_cable_vpe_al_50kv\": (1 - oh[\"hv\"]) * al[\"hv\"] * q[\"hv\"],\n",
    "        \"land_cable_oil_cu_150kv\": (1 - oh[\"hv\"]) * (1 - al[\"hv\"]) * q[\"hv\"],\n",
    "        \"transformer_250mva\": q[\"transformer_250mva\"],\n",
    "        # MV\n",
    "        \"overhead_line_10kv\": oh[\"mv\"] * q[\"mv\"],\n",
    "        \"land_cable_vpe_al_10kv\": (1 - oh[\"mv\"]) * al[\"mv\"] * q[\"mv\"],\n",
    "        \"land_cable_epr_cu_11kv\": (1 - oh[\"mv\"]) * (1 - al[\"mv\"]) * q[\"land_cable_epr_cu_11kv\"],\n",
    "        \"transformer_40mva\": q[\"transformer_40mva\"],\n",
    "        \"gas_insulated_switchgear_420kv\": q[\"gas_insulated_switchgear_420kv\"],\n",
    "        \"substation_mv\": q[\"substation_mv\"],\n",
    "        # LV\n",
    "        \"overhead_line_04kv\": oh[\"lv\"] * q[\"lv\"],\n",
    "        \"land_cable_vpe_al_04kv\": (1 - oh[\"lv\"]) * al[\"lv\"] * q[\"lv\"],\n",
    "        \"land_cable_vpe_cu_1kv\": (1 - oh[\"lv\"]) * (1 - al[\"lv\"]) * q[\"lv\"],\n",
    "        \"transformer_315kva\": q[\"transformer_315kva\"],\n",
    "        \"substation_lv\": q[\"substation_lv\"],\n",
    "    }\n",
    "\n",
    "print(\"Grid compositions computed successfully.\")\n",
    "print(f\"Uncertainty range: 5% in 2023 -> 20% in 2045 (triangular distribution)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating grid nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid status quo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_status_quo = bd.Database(\"grid_status_quo\")\n",
    "background_2023 = bd.Database(\"ei310_SSP2_NPi_2023\") # common basis: ssp2 base scenario\n",
    "\n",
    "create_component_nodes(background_2023.name, db_status_quo.name)\n",
    "\n",
    "node_code = 'grid_status_quo'\n",
    "node_name = node_code\n",
    "\n",
    "try:\n",
    "    grid = db_status_quo.new_node(code=node_code, name=node_name)\n",
    "except:\n",
    "    existing_node = db_status_quo.get(node_code)\n",
    "    existing_node.delete()\n",
    "    grid = db_status_quo.new_node(code=node_code, name=node_name)\n",
    "grid.save()\n",
    "grid.new_edge(input=grid, amount=1, type='production').save()\n",
    "for key, value in grid_compositions[2023].items():\n",
    "    grid.new_edge(input=db_status_quo.get(key), amount=value, type='technosphere').save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregated material nodes for status quo, needed for the sankey diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_exchanges = {\n",
    "    'aluminium': {},\n",
    "    'steel': {},\n",
    "    'concrete': {},\n",
    "    'copper': {},\n",
    "    'plastics': {}\n",
    "}\n",
    "\n",
    "grid = bd.get_node(code=\"grid_status_quo\")\n",
    "for component_exchange in grid.technosphere():\n",
    "    for material_exchange in component_exchange.input.technosphere():\n",
    "        name = material_exchange.input['name'].lower()\n",
    "        key = None\n",
    "        if \"aluminium\" in name:\n",
    "            key = 'aluminium'\n",
    "        elif \"steel\" in name or \"iron\" in name:\n",
    "            key = 'steel'\n",
    "        elif \"concrete\" in name:\n",
    "            key = 'concrete'\n",
    "        elif \"copper\" in name:\n",
    "            key = 'copper'\n",
    "        elif \"polyethylene\" in name or \"polypropylene\" in name or \"plastic\" in name:\n",
    "            key = 'plastics'\n",
    "\n",
    "        total_amount = material_exchange.amount * component_exchange.amount\n",
    "        \n",
    "        if key:\n",
    "            if material_exchange.input in material_exchanges[key]:\n",
    "                material_exchanges[key][material_exchange.input] += total_amount\n",
    "            else:\n",
    "                material_exchanges[key][material_exchange.input] = total_amount\n",
    "        else:\n",
    "            if material_exchange.input in material_exchanges.setdefault('other', {}):\n",
    "                material_exchanges['other'][material_exchange.input] += total_amount\n",
    "            else:\n",
    "                material_exchanges['other'][material_exchange.input] = total_amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_material_nodes = []\n",
    "for name, subexchanges in material_exchanges.items():\n",
    "    try:\n",
    "        mat = db_status_quo.new_node(\n",
    "            name=f\"aggregated material: {name}\"\n",
    "        )\n",
    "    except:\n",
    "        db_status_quo.get(name).delete()\n",
    "        mat = db_status_quo.new_node(\n",
    "            name=f\"aggregated material: {name}\"\n",
    "        )\n",
    "    mat.save()\n",
    "    aggregated_material_nodes.append(mat)\n",
    "    mat.new_exchange(input=mat, amount=1, type=\"production\").save()\n",
    "    for node, value in subexchanges.items():\n",
    "        mat.new_exchange(input=node, amount=value, type=\"technosphere\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid expansion nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributing grid expansion periods to sub-expansion periods that can be linked to prospective databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current year\n",
    "current_year = 2023\n",
    "expansion_period_1 = 2037 - current_year\n",
    "expansion_period_2 = 2045 - 2037\n",
    "\n",
    "# Target years for the distribution\n",
    "years_2037 = [2023, 2025, 2030, 2035, 2037]\n",
    "timespan_2037 = years_2037[-1] - years_2037[0]\n",
    "years_2045 = [2037, 2040, 2045]\n",
    "timespan_2045 = years_2045[-1] - years_2045[0]\n",
    "\n",
    "distributed_components = {}\n",
    "for index, year in enumerate(years_2037):\n",
    "    if year < 2037:\n",
    "        year_data = {}\n",
    "        duration = years_2037[index+1] - year \n",
    "        factor = duration / timespan_2037\n",
    "        \n",
    "        year_data = {}\n",
    "        for component, total_value in grid_compositions[2037].items():\n",
    "            year_data[component] = total_value * factor\n",
    "        distributed_components[year] = year_data\n",
    "        \n",
    "for index, year in enumerate(years_2045):\n",
    "    if year < 2045:\n",
    "        year_data = {}\n",
    "        duration = years_2045[index+1] - year \n",
    "        factor = duration / timespan_2045\n",
    "        \n",
    "        year_data = {}\n",
    "        for component, total_value in grid_compositions[2045].items():\n",
    "            year_data[component] = total_value * factor\n",
    "        distributed_components[year] = year_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the results for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.dump(distributed_components, open(\"data/results/distributed_components.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure the distributed numbers sum up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_distributed_sums(components, distributed_data):\n",
    "    original_totals = {}\n",
    "    for year in components:\n",
    "        if year != 2023:\n",
    "            for component, value in components[year].items():\n",
    "                original_totals[component] = original_totals.get(component, 0) + value\n",
    "\n",
    "    distributed_sums = {component: 0 for component in original_totals.keys()}\n",
    "    for year in distributed_data.values():\n",
    "        for component, value in year.items():\n",
    "            distributed_sums[component] += value\n",
    "\n",
    "    all_passed = True\n",
    "    for component, total in original_totals.items():\n",
    "        if not round(distributed_sums[component], 1) == round(total, 1):\n",
    "            print(f\"Test failed for {component}: distributed sum {distributed_sums[component]} != original total {total}\")\n",
    "            all_passed = False\n",
    "    assert all_passed\n",
    "\n",
    "test_result = test_distributed_sums(grid_compositions, distributed_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To link the prospective grid activities to the correct background databases, we need the info what database represents what year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_db_time_mapping = {\n",
    "    'ei310_SSP2_NPi_2023': 2023,\n",
    "    'ei310_SSP2_NPi_2025': 2025,\n",
    "    'ei310_SSP2_NPi_2030': 2030,\n",
    "    'ei310_SSP2_NPi_2035': 2035,\n",
    "    'ei310_SSP2_NPi_2037': 2037,\n",
    "    'ei310_SSP2_NPi_2040': 2040,\n",
    "    #    \n",
    "    'ei310_SSP2_PkBudg1000_2023': 2023,\n",
    "    'ei310_SSP2_PkBudg1000_2025': 2025,\n",
    "    'ei310_SSP2_PkBudg1000_2030': 2030,\n",
    "    'ei310_SSP2_PkBudg1000_2035': 2035,\n",
    "    'ei310_SSP2_PkBudg1000_2037': 2037,\n",
    "    'ei310_SSP2_PkBudg1000_2040': 2040,\n",
    "    #\n",
    "    'ei310_SSP2_PkBudg650_2023': 2023,\n",
    "    'ei310_SSP2_PkBudg650_2025': 2025,\n",
    "    'ei310_SSP2_PkBudg650_2030': 2030,\n",
    "    'ei310_SSP2_PkBudg650_2035': 2035,\n",
    "    'ei310_SSP2_PkBudg650_2037': 2037,\n",
    "    'ei310_SSP2_PkBudg650_2040': 2040,\n",
    "}\n",
    "\n",
    "ends_of_expansion_periods = {\n",
    "    2023: 2025,\n",
    "    2025: 2030,\n",
    "    2030: 2035,\n",
    "    2035: 2037,\n",
    "    2037: 2040,\n",
    "    2040: 2045,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the prospective grid activities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup Parameters First ---\n",
    "# Get all unique years from the mapping\n",
    "all_years = sorted(set(background_db_time_mapping.values()))\n",
    "setup_project_parameters(all_years)\n",
    "\n",
    "# --- Clean up old parameter groups ---\n",
    "from bw2data.parameters import Group, ActivityParameter, ParameterizedExchange\n",
    "\n",
    "# Remove old/stale parameter groups that might cause conflicts\n",
    "old_groups = [\"grid_share_parameters\", \"grid_expansion_prospective_params\", \"grid_expansion_static_params\"]\n",
    "for group_name in old_groups:\n",
    "    try:\n",
    "        group = Group.get(name=group_name)\n",
    "        # Delete associated activity parameters\n",
    "        ActivityParameter.delete().where(ActivityParameter.group == group_name).execute()\n",
    "        # Delete associated parameterized exchanges\n",
    "        ParameterizedExchange.delete().where(ParameterizedExchange.group == group_name).execute()\n",
    "        # Delete the group\n",
    "        group.delete_instance()\n",
    "        print(f\"Cleaned up old group: {group_name}\")\n",
    "    except:\n",
    "        pass  # Group doesn't exist, that's fine\n",
    "\n",
    "# --- Create Grid Expansion Database with Parameterized Exchanges ---\n",
    "nodes_prospective_expansion = []\n",
    "db_expansion = bd.Database(\"grid_expansion_prospective\")\n",
    "if db_expansion.name in bd.databases:\n",
    "    del bd.databases[db_expansion.name]\n",
    "db_expansion.register()\n",
    "\n",
    "# Use database-specific parameter group\n",
    "param_group_prospective = \"grid_expansion_prospective_params\"\n",
    "\n",
    "for db_name, year in background_db_time_mapping.items():\n",
    "    scenario = db_name.split(\"_\")[2]\n",
    "    db_components = bd.Database(f\"grid_components_{scenario}_{year}\")\n",
    "    if year != 2023:\n",
    "        db_background = bd.Database(db_name)\n",
    "    else:\n",
    "        db_background = bd.Database(\"ei310_SSP2_NPi_2023\") # choose same basis for status quo\n",
    "\n",
    "    create_component_nodes(db_background.name, db_components.name)\n",
    "\n",
    "    node_code = f\"grid_{scenario}_{ends_of_expansion_periods[year]}\"\n",
    "    node_name = node_code\n",
    "\n",
    "    try:\n",
    "        grid = db_expansion.new_node(code=node_code, name=node_name)\n",
    "    except:\n",
    "        existing_node = db_expansion.get(node_code)\n",
    "        existing_node.delete()\n",
    "        grid = db_expansion.new_node(code=node_code, name=node_name)\n",
    "    grid.save()\n",
    "\n",
    "    nodes_prospective_expansion.append(grid)\n",
    "\n",
    "    grid.new_edge(input=grid, amount=1, type=\"production\").save()\n",
    "    \n",
    "    # Create exchanges with formulas for parameterized components\n",
    "    for key, value in distributed_components[year].items():\n",
    "        formula = get_formula_for_component(key, year, value)\n",
    "        \n",
    "        if formula:\n",
    "            # Create exchange with formula for parameterized components\n",
    "            edge = grid.new_edge(\n",
    "                input=db_components.get(key), \n",
    "                amount=value,  # Default amount\n",
    "                type=\"technosphere\",\n",
    "                formula=formula,\n",
    "            )\n",
    "        else:\n",
    "            # Fixed components (transformers, substations) - no formula\n",
    "            edge = grid.new_edge(\n",
    "                input=db_components.get(key), \n",
    "                amount=value, \n",
    "                type=\"technosphere\"\n",
    "            )\n",
    "        edge.save()\n",
    "    \n",
    "    # Add this activity to the database-specific parameter group\n",
    "    bd.parameters.add_exchanges_to_group(param_group_prospective, grid)\n",
    "\n",
    "# Recalculate only the specific group we just created\n",
    "ActivityParameter.recalculate(param_group_prospective)\n",
    "print(f\"Created {len(nodes_prospective_expansion)} grid expansion nodes with parameterized exchanges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static expansion for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static expansion for comparison (also parameterized)\n",
    "nodes_static_expansion = []\n",
    "\n",
    "db_static_expansion = bd.Database(f\"grid_expansion_static\")\n",
    "if db_static_expansion.name in bd.databases:\n",
    "    del bd.databases[db_static_expansion.name]\n",
    "db_static_expansion.register()\n",
    "\n",
    "# Use database-specific parameter group\n",
    "param_group_static = \"grid_expansion_static_params\"\n",
    "\n",
    "years = [\n",
    "    2023,\n",
    "    2025,\n",
    "    2030,\n",
    "    2035,\n",
    "    2037,\n",
    "    2040,\n",
    "]\n",
    "\n",
    "for year in years:\n",
    "    node_code = f\"grid_static_{ends_of_expansion_periods[year]}\"\n",
    "    node_name = node_code\n",
    "    try:\n",
    "        grid = db_static_expansion.new_node(code=node_code, name=node_name)\n",
    "    except:\n",
    "        existing_node = db_static_expansion.get(node_code)\n",
    "        existing_node.delete()\n",
    "        grid = db_static_expansion.new_node(code=node_code, name=node_name)\n",
    "    grid.save()\n",
    "\n",
    "    nodes_static_expansion.append(grid)\n",
    "\n",
    "    grid.new_edge(input=grid, amount=1, type=\"production\").save()\n",
    "    \n",
    "    for key, value in distributed_components[year].items():\n",
    "        formula = get_formula_for_component(key, year, value)\n",
    "        \n",
    "        if formula:\n",
    "            # Create exchange with formula for parameterized components\n",
    "            edge = grid.new_edge(\n",
    "                input=db_status_quo.get(key), \n",
    "                amount=value,\n",
    "                type=\"technosphere\",\n",
    "                formula=formula,\n",
    "            )\n",
    "        else:\n",
    "            # Fixed components - no formula\n",
    "            edge = grid.new_edge(\n",
    "                input=db_status_quo.get(key), \n",
    "                amount=value, \n",
    "                type=\"technosphere\"\n",
    "            )\n",
    "        edge.save()\n",
    "    \n",
    "    # Add to database-specific parameter group\n",
    "    bd.parameters.add_exchanges_to_group(param_group_static, grid)\n",
    "\n",
    "# Recalculate only this specific group\n",
    "ActivityParameter.recalculate(param_group_static)\n",
    "print(f\"Created {len(nodes_static_expansion)} static expansion nodes with parameterized exchanges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add electricity mixes for comparison of emissions per kWh electricity\n",
    "\n",
    "We base the assessment on the German market for electricity, low voltage and remove all grid-related exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_mix_lv_2023 = bd.get_node(database=\"ei310_SSP2_NPi_2023\", name=\"market group for electricity, low voltage\", location=\"DEU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_mix_mv_2023 = bd.get_node(database=\"ei310_SSP2_NPi_2023\", name=\"market group for electricity, low voltage\", location=\"DEU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"new_mixes\" in bd.databases:\n",
    "    del bd.databases[\"new_mixes\"]\n",
    "db_new_mixes = bd.Database(\"new_mixes\")\n",
    "db_new_mixes.register()\n",
    "\n",
    "dbs = [\"ei310_SSP2_NPi_2023\", \"ei310_SSP2_NPi_2045\", \"ei310_SSP2_PkBudg1000_2045\", \"ei310_SSP2_PkBudg650_2045\"]\n",
    "\n",
    "for db, scenario, year in zip(dbs, [\"SS2_NPi\", \"SSP2_NPi\", \"SSP2-PkBudg1000\", \"SSP2-PkBudg650\"], [2023, 2045, 2045, 2045]):\n",
    "    # MV LEVEL\n",
    "    old_mix_mv_2023 = bd.get_node(database=db, name=\"market group for electricity, medium voltage\", location=\"DEU\")\n",
    "    activity_mv_name = f'market group for electricity, medium voltage DE {year} {scenario} NO GRID'\n",
    "    activity_mv_code = f'el_mv_{year}_DE_{scenario}'\n",
    "\n",
    "    try:\n",
    "        new_mix_mv = db_new_mixes.new_node(code=activity_mv_code, name=activity_mv_name)\n",
    "    except:\n",
    "        existing_activity = db_new_mixes.get(activity_mv_code)\n",
    "        existing_activity.delete()\n",
    "        new_mix_mv = db_new_mixes.new_activity(code=activity_mv_code, name=activity_mv_name, unit='kilowatt hour', location=\"DEU\", **{'reference product': activity_mv_name})\n",
    "    new_mix_mv.save()\n",
    "\n",
    "    for exc in old_mix_mv_2023.exchanges():\n",
    "        if 'transmission network' in exc['name'] or 'sulfur hexafluoride' in exc['name'].lower():\n",
    "            continue\n",
    "        if exc['type'] == 'production':\n",
    "            new_mix_mv.new_edge(input=new_mix_mv.key, amount=1, type='production').save()\n",
    "        elif exc[\"name\"] == \"market group for electricity, medium voltage\":\n",
    "            new_mix_mv.new_exchange(input=new_mix_mv, amount=exc['amount'], type=exc['type']).save()\n",
    "        else:\n",
    "            new_mix_mv.new_exchange(input=exc['input'], amount=exc['amount'], type=exc['type']).save()\n",
    "\n",
    "    # LV LEVEL\n",
    "    old_mix_lv = bd.get_node(database=db, name=\"market group for electricity, low voltage\", location=\"DEU\") \n",
    "    activity_lv_name = f'market group for electricity, low voltage DE {year} {scenario} NO GRID'\n",
    "    activity_lv_code = f'el_lv_{year}_DE_{scenario}'\n",
    "\n",
    "    try:\n",
    "        new_mix_lv = db_new_mixes.new_node(code=activity_lv_code, name=activity_lv_name)\n",
    "    except:\n",
    "        existing_activity = db_new_mixes.get(activity_lv_code)\n",
    "        existing_activity.delete()\n",
    "        new_mix_lv = db_new_mixes.new_activity(code=activity_lv_code, name=activity_lv_name, unit='kilowatt hour', location=\"DEU\", **{'reference product': activity_lv_name})\n",
    "    new_mix_lv.save()\n",
    "\n",
    "    for exc in old_mix_lv.exchanges():\n",
    "        if 'distribution network' in exc['name'] or 'sulfur hexafluoride' in exc['name'].lower():\n",
    "            continue\n",
    "        if exc['type'] == 'production':\n",
    "            new_mix_lv.new_edge(input=new_mix_lv.key, amount=1, type='production').save()\n",
    "        elif exc[\"name\"] == \"market group for electricity, low voltage\":\n",
    "            new_mix_lv.new_exchange(input=new_mix_lv, amount=exc['amount'], type=exc['type']).save()\n",
    "        elif exc[\"name\"] == \"market group for electricity, medium voltage\":\n",
    "            new_mix_lv.new_exchange(input=new_mix_mv, amount=exc['amount'], type=exc['type']).save()\n",
    "        else:\n",
    "            new_mix_lv.new_exchange(input=exc['input'], amount=exc['amount'], type=exc['type']).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add additional scenario for recycled material shares in Aluminium Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shares_secondary_alu = { # from IAI Report \"Aluminium Sector Greenhouse Gas Pathways to 2050\"\n",
    "    \"SSP2-PkBudg650\": { # 1.5C scenario from original report\n",
    "        2018: 0.33,\n",
    "        2030: 0.43,\n",
    "        2035: 0.45,\n",
    "        2040: 0.48,\n",
    "        2045: 0.51,\n",
    "    },\n",
    "    \"SSP2-PkBudg1000\": { # <2C scenario from original report\n",
    "        2018: 0.33,\n",
    "        2030: 0.44,\n",
    "        2035: 0.47,\n",
    "        2040: 0.48,\n",
    "        2045: 0.50,\n",
    "    },\n",
    "    \"SSP2-NPi\": { # BAU scenario from original report\n",
    "        2018: 0.33,\n",
    "        2030: 0.42,\n",
    "        2035: 0.44,\n",
    "        2040: 0.45,\n",
    "        2045: 0.46,\n",
    "    }\n",
    "}\n",
    "\n",
    "def extract_scenario_from_db_name(db_name: str) -> str:\n",
    "    parts = db_name.split(\"_\")\n",
    "    scenario_part = parts[1]  # e.g., \"SSP2\"\n",
    "    scenario_type_part = parts[2]  # e.g., \"NPi\", \"PkBudg1000\", \"PkBudg650\"\n",
    "    return f\"{scenario_part}-{scenario_type_part}\"\n",
    "\n",
    "def interpolate_scrap_share(year: int, scenario: str) -> float:\n",
    "    shares = shares_secondary_alu[scenario]\n",
    "    years = sorted(shares.keys()) \n",
    "    \n",
    "    if year in shares:\n",
    "        return shares[year]\n",
    "    \n",
    "    for i in range(len(years) - 1):\n",
    "        if years[i] < year < years[i + 1]:\n",
    "            year_start = years[i]\n",
    "            year_end = years[i + 1]\n",
    "            share_start = shares[year_start]\n",
    "            share_end = shares[year_end]\n",
    "            # Linear interpolation\n",
    "            interpolated_share = share_start + (share_end - share_start) * ((year - year_start) / (year_end - year_start))\n",
    "            return interpolated_share\n",
    "    \n",
    "\n",
    "for db_name, year in background_db_time_mapping.items():    \n",
    "    # 1. Group the exchanges\n",
    "    alu = bd.Database(db_name).get(name=\"market for aluminium, wrought alloy\", location=\"GLO\")\n",
    "    scrap_exchanges = [exc for exc in alu.technosphere() if \"treatment of aluminium scrap\" in exc.input['name'].lower()]\n",
    "    primary_exchanges = [exc for exc in alu.technosphere() if \"aluminium ingot, primary\" in exc.input['name'].lower()]\n",
    "    \n",
    "    # 2. Get current sub-totals to determine internal proportions\n",
    "    current_scrap_total = sum(exc.amount for exc in scrap_exchanges)\n",
    "    current_primary_total = sum(exc.amount for exc in primary_exchanges)\n",
    "    \n",
    "    # 3. Define the new target shares (Target Total = 1)\n",
    "    new_scrap_share = interpolate_scrap_share(year=year, scenario=extract_scenario_from_db_name(db_name))\n",
    "    new_primary_share = 1 - new_scrap_share\n",
    "    \n",
    "    # 4. Scale Scrap Exchanges\n",
    "    if current_scrap_total > 0:\n",
    "        for exc in scrap_exchanges:\n",
    "            proportion = exc.amount / current_scrap_total\n",
    "            new_amount = proportion * new_scrap_share\n",
    "            print(f\"  [Scrap] Scaling {exc.input['location']} {exc.input['name'][:30]}...: {exc.amount:.4f} -> {new_amount:.4f}\")\n",
    "            exc[\"amount\"] = new_amount\n",
    "            exc.save()\n",
    "\n",
    "    # 5. Scale Primary Exchanges\n",
    "    if current_primary_total > 0:\n",
    "        for exc in primary_exchanges:\n",
    "            proportion = exc.amount / current_primary_total\n",
    "            new_amount = proportion * new_primary_share\n",
    "            print(f\"  [Prim] Scaling {exc.input['location']} {exc.input['name'][:30]}...: {exc.amount:.4f} -> {new_amount:.4f}\")\n",
    "            exc[\"amount\"] = new_amount\n",
    "            exc.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating materials for faster monte carlo runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dbs = [db for db in bd.databases if db.startswith(\"agg_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for db in agg_dbs:\n",
    "    del bd.databases[db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2calc as bc\n",
    "\n",
    "method = ('IPCC 2021', 'climate change', 'GWP 100a, incl. H and bio CO2')\n",
    "co2 = bd.get_node(database=\"ecoinvent-3.10.1-biosphere\", name=\"Carbon dioxide, fossil\", categories=(\"air\",))\n",
    "\n",
    "for db_name in background_db_time_mapping.keys():\n",
    "    bg_inputs = list(load_inputs_from_background(db_name).values())\n",
    "    new_db = bd.Database(\"agg_\" + db_name)\n",
    "    new_db.register()\n",
    "    lca = bc.LCA({bg_inputs[0]: 1}, method=method)\n",
    "    lca.lci(factorize=True)\n",
    "    for inp in bg_inputs:\n",
    "        lca.redo_lcia(demand={inp.id: 1})\n",
    "        agg_act = new_db.new_node(name=\"agg\" + inp['name'])\n",
    "        agg_act.save()\n",
    "        agg_act.new_edge(input=agg_act, amount=1, type=\"production\").save()\n",
    "        agg_act.new_edge(input=co2, amount=lca.score, type=\"biosphere\").save()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_dbs = [ \n",
    " 'grid_components_NPi_2023',\n",
    " 'grid_components_NPi_2025',\n",
    " 'grid_components_NPi_2030',\n",
    " 'grid_components_NPi_2035',\n",
    " 'grid_components_NPi_2037',\n",
    " 'grid_components_NPi_2040',\n",
    " 'grid_components_PkBudg1000_2023',\n",
    " 'grid_components_PkBudg1000_2025',\n",
    " 'grid_components_PkBudg1000_2030',\n",
    " 'grid_components_PkBudg1000_2035',\n",
    " 'grid_components_PkBudg1000_2037',\n",
    " 'grid_components_PkBudg1000_2040',\n",
    " 'grid_components_PkBudg650_2023',\n",
    " 'grid_components_PkBudg650_2025',\n",
    " 'grid_components_PkBudg650_2030',\n",
    " 'grid_components_PkBudg650_2035',\n",
    " 'grid_components_PkBudg650_2037',\n",
    " 'grid_components_PkBudg650_2040',]\n",
    "\n",
    "# for db in comp_dbs:\n",
    "#     del bd.databases[\"agg_\" + db]\n",
    "    \n",
    "for db_name in comp_dbs:\n",
    "    new_db = bd.Database(\"agg_\" + db_name)\n",
    "    new_db.register()\n",
    "    for act in bd.Database(db_name):\n",
    "        try:\n",
    "            new_db.get(name=\"agg\" + act['name'])\n",
    "            print(f\"Aggregated activity for {act['name'], db_name} already exists, skipping...\")\n",
    "            continue\n",
    "        except:\n",
    "            pass\n",
    "        new_act = new_db.new_node(name=\"agg\" + act['name'])\n",
    "        new_act.save()\n",
    "        new_act.new_edge(input=new_act, amount=1, type=\"production\").save()\n",
    "        for exc in act.technosphere():\n",
    "            try:\n",
    "                agg_input = bd.get_node(database=\"agg_\" + exc.input['database'], name=\"agg\" + exc.input['name'])\n",
    "            except:\n",
    "                print(f\"Input {exc.input['name']} not found in agg_{exc.input['database']}, skipping...\")\n",
    "                raise\n",
    "            new_act.new_edge(input=agg_input, amount=exc.amount, type=\"technosphere\").save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"agg_grid_expansion_prospective\" in bd.databases:\n",
    "    del bd.databases[\"agg_grid_expansion_prospective\"]\n",
    "\n",
    "# Clean up old parameter group if it exists\n",
    "from bw2data.parameters import Group, ActivityParameter, ParameterizedExchange\n",
    "agg_param_group = \"agg_grid_expansion_prospective_params\"\n",
    "try:\n",
    "    group = Group.get(name=agg_param_group)\n",
    "    ActivityParameter.delete().where(ActivityParameter.group == agg_param_group).execute()\n",
    "    ParameterizedExchange.delete().where(ParameterizedExchange.group == agg_param_group).execute()\n",
    "    group.delete_instance()\n",
    "    print(f\"Cleaned up old group: {agg_param_group}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "new_db = bd.Database(\"agg_grid_expansion_prospective\")\n",
    "new_db.register()\n",
    "\n",
    "old_expansion_db = bd.Database(\"grid_expansion_prospective\")\n",
    "\n",
    "for act in old_expansion_db:\n",
    "    new_act = new_db.new_node(name=\"agg\" + act['name'])  # grid node for a specific year\n",
    "    new_act.save()\n",
    "    new_act.new_edge(input=new_act, amount=1, type=\"production\").save()\n",
    "    \n",
    "    has_formula = False\n",
    "    for exc in act.technosphere():\n",
    "        agg_input = bd.get_node(database=\"agg_\" + exc.input['database'], name=\"agg\" + exc.input['name'])\n",
    "        \n",
    "        # Copy the formula if it exists, along with the amount\n",
    "        if exc.get(\"formula\"):\n",
    "            new_act.new_edge(\n",
    "                input=agg_input, \n",
    "                amount=exc.amount, \n",
    "                type=\"technosphere\",\n",
    "                formula=exc[\"formula\"]\n",
    "            ).save()\n",
    "            has_formula = True\n",
    "        else:\n",
    "            new_act.new_edge(\n",
    "                input=agg_input, \n",
    "                amount=exc.amount, \n",
    "                type=\"technosphere\"\n",
    "            ).save()\n",
    "    \n",
    "    # Add to parameter group if this activity has any formulas\n",
    "    if has_formula:\n",
    "        bd.parameters.add_exchanges_to_group(agg_param_group, new_act)\n",
    "\n",
    "# Recalculate the aggregated parameter group\n",
    "try:\n",
    "    ActivityParameter.recalculate(agg_param_group)\n",
    "    print(f\"Created aggregated grid expansion nodes with parameterized exchanges.\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: Parameter recalculation skipped or failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding uncertainty info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "for sub_period in bd.Database(\"agg_grid_expansion_prospective\"):\n",
    "        for comp_exc in sub_period.technosphere():\n",
    "            for prop in [\"uncertainty type\", \"loc\", \"scale\", \"shape\", \"minimum\", \"maximum\"]:\n",
    "                if comp_exc.get(prop):\n",
    "                    del comp_exc[prop]\n",
    "            comp_exc.save()\n",
    "            for mat_exc in comp_exc.input.technosphere():\n",
    "                for prop in [\"uncertainty type\", \"loc\", \"scale\", \"shape\", \"minimum\", \"maximum\"]:\n",
    "                    if mat_exc.get(prop):\n",
    "                        del mat_exc[prop]\n",
    "                mat_exc.save()\n",
    "                for bios_exc in mat_exc.input.biosphere():\n",
    "                    for prop in [\"uncertainty type\", \"loc\", \"scale\", \"shape\", \"minimum\", \"maximum\"]:\n",
    "                        if bios_exc.get(prop):\n",
    "                            del bios_exc[prop]\n",
    "                    bios_exc.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncertainty_factor(year, base_uncertainty=0.1, final_uncertainty=0.35, start_year=2023, end_year=2045):\n",
    "        years_total = end_year - start_year\n",
    "        years_elapsed = year - start_year\n",
    "        uncertainty_factor = base_uncertainty + (final_uncertainty - base_uncertainty) * (years_elapsed / years_total)\n",
    "        return uncertainty_factor\n",
    "    \n",
    "for sub_period in bd.Database(\"agg_grid_expansion_prospective\"):\n",
    "    \n",
    "    if not sub_period[\"name\"].startswith(\"agggrid_\"):\n",
    "        continue\n",
    "    \n",
    "    year = int(sub_period['name'].split(\"_\")[-1])\n",
    "    for comp_exc in sub_period.technosphere(): # GRID EXPANSION NUMBERS\n",
    "        comp_exc[\"uncertainty type\"] = 5 # Triangular distribution\n",
    "        comp_exc[\"loc\"] = comp_exc.amount\n",
    "        comp_exc[\"scale\"] = np.nan\n",
    "        comp_exc[\"shape\"] = np.nan\n",
    "        mini = comp_exc.amount - comp_exc.amount * get_uncertainty_factor(year, base_uncertainty=0.05, final_uncertainty=0.20)\n",
    "        maxi = comp_exc.amount + comp_exc.amount * get_uncertainty_factor(year, base_uncertainty=0.05, final_uncertainty=0.20)\n",
    "        if comp_exc.amount < 0:\n",
    "            mini, maxi = maxi, mini  # swap for negative amounts\n",
    "        assert mini <= maxi, f\"Minimum {mini} is not less than maximum {maxi} for component {comp_exc.input['name']} in year {year}\"\n",
    "        comp_exc[\"minimum\"] = mini\n",
    "        comp_exc[\"maximum\"] = maxi\n",
    "        comp_exc.save()\n",
    "        \n",
    "        for mat_exc in comp_exc.input.technosphere(): # COMPONENT MATERIAL DEMANDS\n",
    "            mat_exc[\"uncertainty type\"] = 5 # Triangular distribution\n",
    "            mat_exc[\"loc\"] = mat_exc.amount\n",
    "            mat_exc[\"scale\"] = np.nan\n",
    "            mat_exc[\"shape\"] = np.nan\n",
    "            mini = mat_exc.amount - mat_exc.amount * get_uncertainty_factor(year, base_uncertainty=0.01, final_uncertainty=0.05)\n",
    "            maxi = mat_exc.amount + mat_exc.amount * get_uncertainty_factor(year, base_uncertainty=0.01, final_uncertainty=0.05)\n",
    "            if mat_exc.amount < 0:\n",
    "                mini, maxi = maxi, mini  # swap for negative amounts\n",
    "            assert mini <= maxi, f\"Minimum {mini} is not less than maximum {maxi} for material {mat_exc.input['name']} in year {year}\"\n",
    "            mat_exc[\"minimum\"] = mini\n",
    "            mat_exc[\"maximum\"] = maxi\n",
    "            mat_exc.save()\n",
    "            \n",
    "            for emission in mat_exc.input.biosphere(): # MATERIAL GHG EMISSIONS\n",
    "                emission[\"uncertainty type\"] = 5 # Triangular distribution\n",
    "                emission[\"loc\"] = emission.amount\n",
    "                emission[\"scale\"] = np.nan\n",
    "                emission[\"shape\"] = np.nan\n",
    "                mini = emission.amount - emission.amount * get_uncertainty_factor(year, base_uncertainty=0.05, final_uncertainty=0.2)\n",
    "                maxi = emission.amount + emission.amount * get_uncertainty_factor(year, base_uncertainty=0.05, final_uncertainty=0.2)\n",
    "                if emission.amount < 0:\n",
    "                    mini, maxi = maxi, mini  # swap for negative amounts\n",
    "                assert mini <= maxi, f\"Minimum {mini} is not less than maximum {maxi} for emission {emission.input['name']} in year {year}\"\n",
    "                emission[\"minimum\"] = mini\n",
    "                emission[\"maximum\"] = maxi\n",
    "                emission.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating aggregated grid expansion nodes over all expansion periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in db:\n",
    "    if \"expansion\" in node['name']:\n",
    "        node.delete()\n",
    "\n",
    "exp_npi = db.new_node(name=\"expansion_NPi\")\n",
    "exp_npi.new_edge(input=exp_npi, amount=1, type=\"production\").save()\n",
    "\n",
    "exp_pkbudg1000 = db.new_node(name=\"expansion_PkBudg1000\")\n",
    "exp_pkbudg1000.new_edge(input=exp_pkbudg1000, amount=1, type=\"production\").save()\n",
    "\n",
    "exp_pkbudg650 = db.new_node(name=\"expansion_PkBudg650\")\n",
    "exp_pkbudg650.new_edge(input=exp_pkbudg650, amount=1, type=\"production\").save()\n",
    "\n",
    "for node in db:\n",
    "    if node['name'].startswith(\"agggrid_NPi_\"):\n",
    "        exp_npi.new_edge(input=node, amount=1, type=\"technosphere\").save()\n",
    "    elif node['name'].startswith(\"agggrid_PkBudg1000_\"):\n",
    "        exp_pkbudg1000.new_edge(input=node, amount=1, type=\"technosphere\").save()\n",
    "    elif node['name'].startswith(\"agggrid_PkBudg650_\"):\n",
    "        exp_pkbudg650.new_edge(input=node, amount=1, type=\"technosphere\").save()\n",
    "\n",
    "exp_npi.save()\n",
    "exp_pkbudg1000.save()\n",
    "exp_pkbudg650.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "premise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
